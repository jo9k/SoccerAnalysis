{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content\n",
    "* [Imports and loading dataset](#import-load)\n",
    "* [Exploration of the dataset](#data-exploration)\n",
    "* [Engineering the features](#feature-engineering)\n",
    "* [Model creation and fitting](#model-learning)\n",
    "\n",
    "    -[imports and functions](#model-learning-top)\n",
    "    \n",
    "    -[setup](#model-learning-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT & LOAD<a class=\"anchor\" id=\"import-load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Import libraries\n",
    "# SQL\n",
    "import sqlite3\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Nice Tables\n",
    "from ipy_table import *\n",
    "\n",
    "# Import and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data (make sure you have downloaded database.sqlite)\n",
    "with sqlite3.connect(r'C:/Users/ernest.chocholowski/Desktop/Datasets/Soccer/database.sqlite') as con:\n",
    "    country_df = pd.read_sql_query(\"SELECT * from Country\", con)\n",
    "    matches_df = pd.read_sql_query(\"SELECT * from Match\", con)\n",
    "    league_df = pd.read_sql_query(\"SELECT * from League\", con)\n",
    "    team_df = pd.read_sql_query(\"SELECT * from Team\", con)\n",
    "    player_df = pd.read_sql_query(\"select * from Player\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = [country_df, matches_df, league_df, team_df, player_df]\n",
    "country_df.dfname = 'country_df'\n",
    "matches_df.dfname = 'matches_df'\n",
    "league_df.dfname = 'league_df' \n",
    "team_df.dfname = 'team_df' \n",
    "player_df.dfname = 'player_df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION<a class=\"anchor\" id=\"data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_df\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 2 columns):\n",
      "id      11 non-null int64\n",
      "name    11 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 256.0+ bytes\n",
      "None\n",
      "----------------------------------------\n",
      "matches_df\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25979 entries, 0 to 25978\n",
      "Columns: 115 entries, id to BSA\n",
      "dtypes: float64(96), int64(9), object(10)\n",
      "memory usage: 22.8+ MB\n",
      "None\n",
      "----------------------------------------\n",
      "league_df\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 3 columns):\n",
      "id            11 non-null int64\n",
      "country_id    11 non-null int64\n",
      "name          11 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 344.0+ bytes\n",
      "None\n",
      "----------------------------------------\n",
      "team_df\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 5 columns):\n",
      "id                  299 non-null int64\n",
      "team_api_id         299 non-null int64\n",
      "team_fifa_api_id    288 non-null float64\n",
      "team_long_name      299 non-null object\n",
      "team_short_name     299 non-null object\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 11.8+ KB\n",
      "None\n",
      "----------------------------------------\n",
      "player_df\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11060 entries, 0 to 11059\n",
      "Data columns (total 7 columns):\n",
      "id                    11060 non-null int64\n",
      "player_api_id         11060 non-null int64\n",
      "player_name           11060 non-null object\n",
      "player_fifa_api_id    11060 non-null int64\n",
      "birthday              11060 non-null object\n",
      "height                11060 non-null float64\n",
      "weight                11060 non-null int64\n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 604.9+ KB\n",
      "None\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    print(df.dfname)\n",
    "    print(df.info())\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING<a class=\"anchor\" id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing libraries\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, Imputer, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_numeric (dataset, formula):\n",
    "    \"\"\"\n",
    "    Impute numeric values in a dataset usinng linear regression\n",
    "    dataset = Pandas Dataframe\n",
    "    formula e.g. 'Y ~ X1 + X2'\n",
    "    \"\"\"\n",
    "    import statsmodels.formula.api as smf\n",
    "    import pandas as pd\n",
    "    \n",
    "    lm = smf.ols(formula = formula, data = dataset)\n",
    "    res = lm.fit()\n",
    "    \n",
    "    temp_train = dataset[pd.isnull(dataset).any(axis=1)].copy()\n",
    "    temp_train = temp_train.drop(formula.split(None, 1)[0], axis=1).copy()\n",
    "    \n",
    "    var_pred = res.predict(temp_train)\n",
    "    var_pred = var_pred.round(decimals=0)\n",
    "    \n",
    "    dataset[formula.split(None, 1)[0]].fillna(var_pred, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_win (row):\n",
    "    if row['home_team_goal'] > row['away_team_goal']:\n",
    "        return 'WIN'\n",
    "    if row['home_team_goal'] == row['away_team_goal']:\n",
    "        return 'DRAW'\n",
    "    if row['home_team_goal'] < row['away_team_goal']:\n",
    "        return 'LOSE'\n",
    "\n",
    "matches_df['RESULT'] = matches_df.apply(lambda row: label_win(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-750af4c4d50a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_mod\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmatches_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mmatches_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "##################VERY BAD########################\n",
    "matches_df.dropna(inplace=True)\n",
    "\n",
    "#labelling\n",
    "var_mod = ['id', 'country_id', 'league_id', 'season', 'stage', 'date',\n",
    "       'match_api_id', 'home_team_api_id', 'away_team_api_id',\n",
    "       'home_team_goal', 'away_team_goal', 'home_player_X1',\n",
    "       'home_player_X2', 'home_player_X3', 'home_player_X4',\n",
    "       'home_player_X5', 'home_player_X6', 'home_player_X7',\n",
    "       'home_player_X8', 'home_player_X9', 'home_player_X10',\n",
    "       'home_player_X11', 'away_player_X1', 'away_player_X2',\n",
    "       'away_player_X3', 'away_player_X4', 'away_player_X5',\n",
    "       'away_player_X6', 'away_player_X7', 'away_player_X8',\n",
    "       'away_player_X9', 'away_player_X10', 'away_player_X11',\n",
    "       'home_player_Y1', 'home_player_Y2', 'home_player_Y3',\n",
    "       'home_player_Y4', 'home_player_Y5', 'home_player_Y6',\n",
    "       'home_player_Y7', 'home_player_Y8', 'home_player_Y9',\n",
    "       'home_player_Y10', 'home_player_Y11', 'away_player_Y1',\n",
    "       'away_player_Y2', 'away_player_Y3', 'away_player_Y4',\n",
    "       'away_player_Y5', 'away_player_Y6', 'away_player_Y7',\n",
    "       'away_player_Y8', 'away_player_Y9', 'away_player_Y10',\n",
    "       'away_player_Y11', 'home_player_1', 'home_player_2',\n",
    "       'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6',\n",
    "       'home_player_7', 'home_player_8', 'home_player_9', 'home_player_10',\n",
    "       'home_player_11', 'away_player_1', 'away_player_2', 'away_player_3',\n",
    "       'away_player_4', 'away_player_5', 'away_player_6', 'away_player_7',\n",
    "       'away_player_8', 'away_player_9', 'away_player_10',\n",
    "       'away_player_11', 'goal', 'shoton', 'shotoff', 'foulcommit', 'card',\n",
    "       'cross', 'corner', 'possession', 'B365H', 'B365D', 'B365A', 'BWH',\n",
    "       'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'PSH',\n",
    "       'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'SJH', 'SJD', 'SJA', 'VCH',\n",
    "       'VCD', 'VCA', 'GBH', 'GBD', 'GBA', 'BSH', 'BSD', 'BSA', 'RESULT']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    mask = ~train_df[i].isnull()\n",
    "    train_df[i][mask] = le.fit_transform(train_df[i][mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LEARNING<a class=\"anchor\" id=\"model-learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS AND FUNCTIONS<a class=\"anchor\" id=\"model-learning-top\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data for train and test\n",
    "def split_data(data, targ):\n",
    "    #set target for training\n",
    "    target = data[targ]\n",
    "\n",
    "    # Import the train_test_split method\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Split data into train (2/3rd of data) and test (1/3rd of data)\n",
    "    return train_test_split(data, target, train_size = 0.75, random_state=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regr_equation(logreg, train, target):\n",
    "    if type(model) is LogisticRegression:\n",
    "        coef = logreg.coef_[0]\n",
    "        intercept = \"{:.2f}\".format(logreg.intercept_[0])\n",
    "    else:\n",
    "        coef = logreg.coef_\n",
    "        intercept = \"{:.2f}\".format(logreg.intercept_)\n",
    "        \n",
    "    output = target.name + ' = ' + str(intercept) + ' + '\n",
    "    coeff_df = pd.DataFrame(train.columns.delete(0))\n",
    "    coeff_df.columns = ['Feature']\n",
    "    coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "    features = coeff_df['Feature'].tolist()\n",
    "    coefficients = coeff_df['Correlation'].tolist()\n",
    "    \n",
    "    for coeff, feature in zip(coefficients, features):\n",
    "        coeff_str = \"{:.2f}\".format(coeff)\n",
    "        output += coeff_str + \"*\" + str(feature) + \" + \"\n",
    "    return output[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(model, X, y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    return confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model (model, data, target, submission_name = None, test=None):\n",
    "   \n",
    "    if test is None:\n",
    "        from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "        train, test, target_train, target_test = split_data(data, target)\n",
    "        model.fit(train, target_train)\n",
    "        #Calc parameters\n",
    "        if type(model) is LogisticRegression:\n",
    "            function_str = regr_equation(model, train, target_train)\n",
    "        elif type(model) is LinearRegression:\n",
    "            function_str = regr_equation(model, train, target_train)\n",
    "        else :\n",
    "            function_str = \"NA\"    \n",
    "\n",
    "        if type(model) is not LinearRegression:\n",
    "            trainset_acc = round(accuracy_score(target_train, model.predict(train)) * 100, 2)\n",
    "            testset_acc = round(accuracy_score(target_test, model.predict(test)) * 100, 2)\n",
    "            conf_matrix = confusion_matrix(target_train, model.predict(train))\n",
    "            conf_matrix = 'TN: '+str(conf_matrix[0][0])+', FP: '+str(conf_matrix[0][1])+ \\\n",
    "                              ', FN: '+str(conf_matrix[1][0])+', TP: '+str(conf_matrix[1][1])\n",
    "        else:\n",
    "            trainset_acc = 'NA'\n",
    "            testset_acc = 'NA'\n",
    "            conf_matrix = \"NA\"\n",
    "\n",
    "        r2_score = r2_score(target_train, model.predict(train))\n",
    "        kaggle = \"not_tested\"\n",
    "\n",
    "        #prints\n",
    "        print(\"-\"*40)\n",
    "        print('Submission name:', submission_name )\n",
    "        print('Regression function:\\n', function_str)\n",
    "        print('Accuracy on train set:', trainset_acc)\n",
    "        print('Accuracy on test set:', testset_acc)\n",
    "        print(\"R2 score:\", r2_score)\n",
    "        print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "        return [submission_name, function_str, str(trainset_acc), str(testset_acc), r2_score, conf_matrix, kaggle]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP<a class=\"anchor\" id=\"model-learning-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "suffix = '_firstTry'\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "modelMLP = MLPClassifier()\n",
    "modelLogReg = LogisticRegression()\n",
    "modelLinReg = LinearRegression()\n",
    "modelSVC = SVC()\n",
    "modellinSVC = LinearSVC()\n",
    "modelKN = KNeighborsClassifier(n_neighbors = 3)\n",
    "modelGNB = GaussianNB()\n",
    "modelPercp = Perceptron()\n",
    "modelSGD = SGDClassifier()\n",
    "modelTree = DecisionTreeClassifier()\n",
    "modelRndForest = RandomForestClassifier()\n",
    "\n",
    "modelXTree = ExtraTreesClassifier()\n",
    "\n",
    "models = {\n",
    "          modelRndForest: \"RandomForest\",\n",
    "          modelLogReg: \"LogisticRegr\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-884359887578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RESULT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmission_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-7f55a17becf0>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, data, target, submission_name, test)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m#Calc parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for model, prefix in models.items():\n",
    "    name=prefix+suffix\n",
    "    outputs.append(test_model(model, matches_df, target='RESULT', submission_name=name))\n",
    "outputs.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for out in outputs:\n",
    "    super_table.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_table(super_table)\n",
    "apply_theme('basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(super_table[1:], columns=super_table[0])\n",
    "#df.to_csv(r'C:/Users/ernest.chocholowski/Desktop/GIT/Titanic/table_eCh.csv', \n",
    "#                      index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
